_target_: src.models.networks.openscene.litmodule.OpenSceneLitModule

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 1e-4

scheduler:
  _target_: torch.optim.lr_scheduler.PolynomialLR
  _partial_: true
  power: 0.9

scheduler_interval: step

net:
  _target_: src.models.networks.openscene.mink_unet.MinkUNet18A
  _partial_: true
  in_channels: ${data.in_channel}
  out_channels: ${model.clip_encoder.text_dim}

loss_cfg:
  caption_loss:
    type: alignment
  seg_loss:
    eval_only: true
    normalize_input: false
    text_clip_path: null
    loss_type: cross_entropy
    ignore_label: ${data.train_dataset.ignore_label}
    learnable_logit: false
  binary_loss: false
  binary_loss_weight: 1.0
  caption_loss_weight: 10.0
  seg_loss_weight: 1.0
  clip_learnable_logit_scale: false
  sync_dist: true
  train_clip_text_alignment: false
  train_clip_image_alignment: false
  clip_text_loss_weight: 1.0
  clip_image_loss_weight: 1.0

clip_encoder:
  model_id: ViT-B/32
  text_dim: 512

compile: false

eval_cfg:
  eval_clip_text_alignment: false
  eval_clip_image_alignment: false

  seg_eval:
    normalize_input: ${model.loss_cfg.seg_loss.normalize_input}
    text_clip_path: ${model.loss_cfg.seg_loss.text_clip_path}

use_prompt: true
