_target_: src.models.networks.warp.litmodule.WarpLitModule

optimizer:
  _target_: src.models.optimization.build_optimizer
  _partial_: true
  optim_cfg:
    LR: 4e-3
    SCHEDULER: adam_onecycle
    OPTIMIZER: adam_onecycle
    WEIGHT_DECAY: 0.0001
    MOMENTUM: 0.9
    STEP_EPOCH: 50
    MULTIPLIER: 0.1
    CLIP_GRAD: False
    PCT_START: 0.39
    DIV_FACTOR: 1
    MOMS: [0.95, 0.85]

scheduler:
  _target_: src.models.optimization.build_scheduler
  _partial_: true
  last_epoch: -1
  optim_cfg: ${model.optimizer.optim_cfg}

scheduler_interval: step

net:
  _target_: src.models.networks.warp.point_convnet.PointConvEncoderDecoderToCLIP
  _partial_: true

  # warp.convnet.models.point_conv_unet.PointConvEncoderDecoder
  backbone_cfg:
    in_channels: 6
    out_channels: 192
    encoder_channels: [16, 32, 48, 64, 80, 96, 112, 128, 144]
    decoder_channels: [144, 160, 172, 192, 192]
    num_encoder_blocks_per_level: [1, 1, 1, 1, 1, 1, 1, 1]
    num_decoder_blocks_per_level: [1, 1, 1, 1]
    # neighbor search args
    neighbor_search_args:
      _target_: warp.convnet.geometry.ops.neighbor_search_continuous.NeighborSearchArgs
      mode: radius
    neighbor_search_radii: [0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]
    # pooling args
    pooling_args:
      _target_: warp.convnet.geometry.ops.point_pool.FeaturePoolingArgs
      pooling_mode: reductions
    downsample_voxel_sizes: [0.05, 0.075, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35]
    num_levels_enc: 8
    num_levels_dec: 4

  # last mlp
  adapter_cfg:
    in_channel: ${model.net.backbone_cfg.out_channels}
    text_channel: 512
    last_norm: true
    normalize_output: true

loss_cfg:
  caption_loss:
    loss_reduction: weighted_sum
  seg_loss:
    eval_only: true # no seg loss training if set to true
    normalize_input: false
    text_clip_path: /datasets/regionplc/text_embed/scannet_clip-ViT-B16_id.pth
    loss_type: cross_entropy
    ignore_label: ${data.train_dataset.ignore_label}
    learnable_logit: false
  binary_loss: false
  caption_loss_weight: 1.0
  seg_loss_weight: 1.0
  sync_dist: true # print synced loss (0.82 it/s vs 84 it/s)

# compile model for faster training with pytorch 2.0
clip_encoder:
  model_id: ViT-B/16
  text_dim: 512

compile: false
