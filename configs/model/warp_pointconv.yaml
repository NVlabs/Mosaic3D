# _target_: src.models.lightning_modules.module_base.LitModuleBase
_target_: src.models.networks.warp.litmodule.WarpLitModule

optimizer:
  _target_: torch.optim.AdamW
  _partial_: true
  lr: 4e-3
  weight_decay: 1e-4

scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  _partial_: true
  max_lr: ${model.optimizer.lr}
  pct_start: 0.39
  anneal_strategy: cos
  div_factor: 1
  final_div_factor: 10000.0

scheduler_interval: step

net:
  _target_: src.models.networks.warp.point_convnet.PointConvUNetToCLIP
  _partial_: true

  # warp.convnet.models.point_conv_unet.PointConvUNet
  backbone_cfg:
    in_channels: 6
    out_channels: 32
    num_levels: 2
    down_channels: [32, 64, 128]
    up_channels: [32, 64, 128]
    # neighbor search args
    neighbor_search_args:
      _target_: warp.convnet.geometry.ops.neighbor_search_continuous.NeighborSearchArgs
      mode: radius
    neighbor_search_radii: [0.2, 0.4]
    # pooling args
    pooling_args:
      _target_: warp.convnet.geometry.ops.point_pool.FeaturePoolingArgs
      pooling_mode: reductions
    downsample_voxel_sizes: [0.1, 0.2]

  # last mlp
  adapter_cfg:
    in_channel: ${model.net.backbone_cfg.out_channels}
    text_channel: 512
    # Automatically set the binary_channel to 1 if binary_loss is enabled
    binary_channel: ${model.loss_cfg.binary_loss}

loss_cfg:
  caption_loss:
    normalize_input: true
    novel_grad_only: true
    ignore_label: ${data.train_dataset.ignore_label}
    learnable_logit: true
  seg_loss:
    normalize_input: false
    text_clip_path: /datasets/regionplc/text_embed/scannet_clip-ViT-B16_id.pth
    loss_type: cross_entropy
    ignore_label: ${data.train_dataset.ignore_label}
    learnable_logit: false
  binary_loss: true
  binary_loss_weight: 1.0
  caption_loss_weight: 0.5
  seg_loss_weight: 1.0
  caption_learnable_logit_scale: true
  clip_learnable_logit_scale: false

# compile model for faster training with pytorch 2.0
text_encoder:
  name: CLIP
  backbone: ViT-B/16

compile: false
